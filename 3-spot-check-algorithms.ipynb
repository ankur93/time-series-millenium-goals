{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Spot Check Algorithms\n",
    "\n",
    "From https://machinelearningmastery.com/process-for-working-through-machine-learning-problems/\n",
    "\n",
    "I use 10 fold cross validation in my test harnesses by default. All experiments (algorithm and dataset combinations) are repeated 10 times and the mean and standard deviation of the accuracy is collected and reported. I also use statistical significance tests to flush out meaningful results from noise. Box-plots are very useful for summarizing the distribution of accuracy results for each algorithm and dataset pair.\n",
    "\n",
    "I spot check algorithms, which means loading up a bunch of standard machine learning algorithms into my test harness and performing a formal experiment. I typically run 10-20 standard algorithms from all the major algorithm families across all the transformed and scaled versions of the dataset I have prepared.\n",
    "\n",
    "The goal of spot checking is to flush out the types of algorithms and dataset combinations that are good at picking out the structure of the problem so that they can be studied in more detail with focused experiments.\n",
    "\n",
    "More focused experiments with well-performing families of algorithms may be performed in this step, but algorithm tuning is left for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/TrainingSet.csv', index_col=0)\n",
    "df.columns = [year[:4] for year in df.columns][:-3] + [col.replace(' ', '_') for col in df.columns.values[-3:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data containing the rows we need to predict\n",
    "df_submission = pd.read_csv('data/SubmissionRows.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_in_data = df.loc[df_submission.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are we trying to achieve?\n",
    "\n",
    " * We have 737 indicators from 206 countries with data from 1972 to 2007.\n",
    " * We would like to predict what these indicators will be in 2008 and 2012.\n",
    "\n",
    "A very simplistic way of predicting the future values of these indicators would be to do a simple linear regression for indicators with more than 1 data point in the last 35 years or use the only data point we have for indicators with a single value.\n",
    "\n",
    "**Let's try to code this simplistic version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(row):\n",
    "    data = row.loc['1972':'2007']\n",
    "    nbr_data_points = data.count()\n",
    "    if nbr_data_points < 2:\n",
    "        pred_2008 = data.dropna().values\n",
    "        pred_2012 = pred_2008\n",
    "    \n",
    "    else:\n",
    "        years = data.dropna().index.values.astype(np.int).reshape(-1, 1)\n",
    "        values = data.dropna().values\n",
    "        \n",
    "        # linear regression\n",
    "        regr = LinearRegression()\n",
    "        regr.fit(years, values)\n",
    "        \n",
    "        # predictions\n",
    "        pred_2008 = regr.predict(np.array([2008]).reshape(-1, 1))\n",
    "        pred_2012 = regr.predict(np.array([2012]).reshape(-1, 1))\n",
    "        \n",
    "    return pred_2008[0], pred_2012[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple_preds = pd.DataFrame(df_submission_in_data.apply(make_prediction, axis=1).tolist(), \\\n",
    "                               index=df_submission_in_data.index, columns=['2008','2012'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(df_train, df_pred, nbr_rows):\n",
    "    np.random.seed(3)\n",
    "    rows_to_plot = np.random.choice(df_train.index.values, nbr_rows, replace=False)\n",
    "    \n",
    "    cmap = get_cmap('Set1')\n",
    "    colors = cmap.colors\n",
    "        \n",
    "    fig, ax = plt.subplots(figsize=(16,10))\n",
    "    for i,j in zip(rows_to_plot, range(nbr_rows)):\n",
    "        if j >= len(colors): j -= len(colors)\n",
    "        ax.plot(df_train.loc[i, '1972':'2007'].dropna().index.astype(int), \n",
    "                df_train.loc[i, '1972':'2007'].dropna().values, \n",
    "                label=df_train.loc[i, 'Country_Name']+ '/' + df_train.loc[i, 'Series_Name'],\n",
    "                marker='o',\n",
    "                linewidth=4,\n",
    "                alpha=0.5,\n",
    "                color=colors[j])\n",
    "                \n",
    "        ax.plot(df_pred.loc[i].index.astype(int), \n",
    "                df_pred.loc[i].values,\n",
    "                marker='s',\n",
    "                linewidth=4,\n",
    "                markersize=10,\n",
    "                color=colors[j])\n",
    "\n",
    "    plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(df_submission_in_data, df_simple_preds, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting one target indicator [Environmental Sustainability (7.8)] for Afghanistan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afghanistan_7_8 = df[ (df[\"Country_Name\"] == \"Afghanistan\") & (df[\"Series_Code\"] == \"7.8\")]\n",
    "df_afghanistan_7_8_1972_to_2007 = df_afghanistan_7_8.loc[:, \"1972\":\"2007\"]\n",
    "df_afghanistan_7_8_1972_to_2007.T.plot(marker=\"o\", title=\"Indicator Environmental Sustainability (7.8) for Afghanistan\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting all indicators except Environmental Sustainability (7.8) for Afghanistan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afghanistan_not_7_8 = df[ (df[\"Country_Name\"] == \"Afghanistan\") & (df[\"Series_Code\"] != \"7.8\")]\n",
    "df_afghanistan_not_7_8_1972_to_2007 = df_afghanistan_not_7_8.loc[:, \"1972\":\"2007\"]\n",
    "df_afghanistan_not_7_8_1972_to_2007.T.plot(marker=\"o\", title=\"Indicator (all other indicators) for Afghanistan\", legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting all indicators except Environmental Sustainability (7.8) for Afghanistan for 2001 to 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afghanistan_not_7_8 = df[ (df[\"Country_Name\"] == \"Afghanistan\") & (df[\"Series_Code\"] != \"7.8\")]\n",
    "df_afghanistan_not_7_8_1972_to_2001 = df_afghanistan_not_7_8.loc[:, \"2001\":\"2007\"]\n",
    "df_afghanistan_not_7_8_1972_to_2001.T.plot(marker=\"o\", title=\"Indicator (all other indicators) for Afghanistan\", legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enlisting top correlated features against target feature [Environmental Sustainability (7.8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_afghanistan = df[ df[\"Country_Name\"] == \"Afghanistan\" ]\n",
    "\n",
    "df_2000_2007 = df_afghanistan.loc[:, \"2000\":\"2007\"]\n",
    "df_2000_2007_clean_index = df_2000_2007.count(axis=1) >= 4\n",
    "\n",
    "\n",
    "data = df_afghanistan[df_2000_2007_clean_index].set_index('Series_Code').loc[:, \"2000\":\"2007\"].T\n",
    "\n",
    "coeff = data.corr().loc[\"7.8\"].abs()\n",
    "coeff.sort_values(inplace=True, ascending=False)\n",
    "coeff.iloc[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the top correlated indicators for Afghanisthan between 2000 to 2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_code_correlated_to_7_8 = coeff.iloc[0:20].index\n",
    "df_afghanistan_indicators_correlated_to_7_8 = df_afghanistan[df_afghanistan.Series_Code.isin(series_code_correlated_to_7_8)]\n",
    "df_afghanistan_indicators_correlated_to_7_8.set_index('Series_Code', inplace=True)\n",
    "plt.rcParams[\"figure.figsize\"] = (14,7)\n",
    "df_afghanistan_indicators_correlated_to_7_8.loc[:, \"2000\":\"2007\"].T.plot(marker=\"o\", legend=True)\n",
    "plt.legend(loc=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize, scale, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = df_afghanistan_indicators_correlated_to_7_8.loc[:,'1972':'2007'].T\n",
    "# print(scaled_df.shape)\n",
    "# display(scaled_df.head(20))\n",
    "scaled_df = scaled_df.dropna()\n",
    "# scaled2_norm_df = pd.DataFrame(normalize(scaled_df, axis=0), columns=scaled_df.columns, index=scaled_df.index)\n",
    "# scaled2_scale_df = pd.DataFrame(scale(scaled_df, axis=0), columns=scaled_df.columns, index=scaled_df.index)\n",
    "scaled2_MinMax_df = pd.DataFrame(MinMaxScaler().fit_transform(scaled_df), columns=scaled_df.columns, index=scaled_df.index)\n",
    "# display(scaled_df.head(20))\n",
    "# scaled2_norm_df.plot(marker=\"o\", legend=True)\n",
    "# scaled2_scale_df.plot(marker=\"o\", legend=True)\n",
    "scaled2_MinMax_df.plot(marker=\"o\", legend=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_columns = [str(item) + \"_pred\" for item in np.array(range(2002,2008))]\n",
    "true_columns = [str(item) for item in range(2002,2008)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(row):\n",
    "    training_data = row.loc['1972':'2002']\n",
    "    test_data = row.loc['2002':'2007']\n",
    "    \n",
    "    nbr_data_points = training_data.count()\n",
    "    if test_data.count()<6 or training_data.count() < 6 :\n",
    "        return  [None]*6\n",
    "    else:\n",
    "        years = training_data.dropna().index.values.astype(np.int).reshape(-1, 1)\n",
    "        values = training_data.dropna().values\n",
    "        \n",
    "        #linear regression\n",
    "        regr = LinearRegression()\n",
    "        regr.fit(years, values)\n",
    "        \n",
    "        #predictions\n",
    "        return regr.predict(np.array(range(2002,2008)).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb 0\n",
    "from pdb import set_trace\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nas(df):\n",
    "    return df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_submission_in_data.dropna(subset=true_columns)\n",
    "df_simple_preds_true_columns = pd.DataFrame(df.apply(make_prediction, axis=1).tolist(), \\\n",
    "                               index=df.index, columns=true_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple_preds_true_columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_df_submission = df_submission_in_data.loc[:,'1972':'2007']\n",
    "scaled_df_submission = scaled_df_submission.dropna()\n",
    "scaled2_MinMax_df_submission = pd.DataFrame(scaler.fit_transform(scaled_df_submission), \\\n",
    "                                            columns=scaled_df_submission.columns, index=scaled_df_submission.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled2_MinMax_df_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled2_MinMax_df_dropna = scaled2_MinMax_df_submission.dropna(subset=true_columns)\n",
    "scaled2_MinMax_df_preds = pd.DataFrame(scaled2_MinMax_df_dropna.apply(make_prediction, axis=1).tolist(), \\\n",
    "                               index=scaled2_MinMax_df_dropna.index, columns=true_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled2_MinMax_df_true_columns = scaled2_MinMax_df_dropna[true_columns]\n",
    "scaled2_MinMax_df_true_columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled2_MinMax_df_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_nas(scaled2_MinMax_df_true_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled2_MinMax_df_true_columns.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_nas(scaled2_MinMax_df_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled2_MinMax_df_preds.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_all_finite(X):\n",
    "    X = np.asanyarray(X)\n",
    "    return (X.dtype.char in np.typecodes['AllFloat'] and np.isfinite(X.sum())\n",
    "            and np.isfinite(X).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(y_true, y_pred):\n",
    "    y_true_df = y_true.copy()\n",
    "    y_pred_df = y_pred.dropna()\n",
    "    validate = y_true_df.loc[y_pred_df.index][true_columns]\n",
    "    assert(assert_all_finite(validate.dropna()))\n",
    "    assert(assert_all_finite(y_pred_df))\n",
    "    return mean_squared_error(validate.dropna(), y_pred_df)\n",
    "# should return the dispersion of the errors as well\n",
    "\n",
    "print(validate(scaled2_MinMax_df_true_columns, scaled2_MinMax_df_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retained_columns = ['Country_Name', 'Series_Code', 'Series_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_in_data_dropna = df_submission_in_data.dropna(subset=true_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_in_data_no_years = df_submission_in_data_dropna[retained_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(scaled2_MinMax_df_true_columns, df_submission_in_data_no_years, left_index=True, \\\n",
    "                     right_index=True, how='outer', suffixes=('',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.dropna(inplace=True)\n",
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_submission_in_data.shape[0] == df_simple_preds.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_predictions(df_submission_in_data, df_simple_preds, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df_merged.shape[0] == scaled2_MinMax_df_preds.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(df_merged, scaled2_MinMax_df_preds, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12/06/2019 Setup polynomial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = scaled2_norm_df\n",
    "y = submission_codes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_columns = [str(item) + \"_pred\" for item in np.array(range(2002,2008))]\n",
    "true_columns = [str(item) for item in range(2002,2008)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(row, model):\n",
    "    training_data = row.loc['1972':'2002']\n",
    "    test_data = row.loc['2002':'2007']\n",
    "    \n",
    "    nbr_data_points = training_data.count()\n",
    "    if test_data.count()<6 or training_data.count() < 6 :\n",
    "        return  [None]*6\n",
    "    else:\n",
    "        years = training_data.dropna().index.values.astype(np.int).reshape(-1, 1)\n",
    "        values = training_data.dropna().values\n",
    "        \n",
    "        model.fit(years, values)\n",
    "        \n",
    "        #predictions\n",
    "        return model.predict(np.array(range(2002,2008)).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_submission_in_data.dropna(subset=true_columns)\n",
    "df_simple_preds_true_columns = pd.DataFrame(df.apply(make_prediction, args=(model,),axis=1).tolist(), \\\n",
    "                               index=df.index, columns=true_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_df_submission = df_submission_in_data.loc[:,'1972':'2007']\n",
    "scaled_df_submission = scaled_df_submission.dropna()\n",
    "scaled_df_submission = scaled_df_submission.dropna(subset=true_columns)\n",
    "scaled_df_submission = pd.DataFrame(scaler.fit_transform(scaled_df_submission), \\\n",
    "                                    columns=scaled_df_submission.columns, index=scaled_df_submission.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df_submission_preds = pd.DataFrame(scaled_df_submission.apply(make_prediction, args=(model,),axis=1).tolist(),\\\n",
    "                               index=scaled_df_submission.index, columns=true_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validate(scaled_df_submission, scaled_df_submission_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_in_data_dropna = df_submission_in_data.dropna(subset=true_columns)\n",
    "df_submission_in_data_no_years = df_submission_in_data_dropna[retained_columns]\n",
    "df_merged = pd.merge(scaled_df_submission, df_submission_in_data_no_years, left_index=True, right_index=True, \\\n",
    "                     how='outer', suffixes=('',''))\n",
    "df_merged.dropna(subset=true_columns,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged = pd.merge(scaled_df_submission, df_submission_in_data_no_years, left_index=True, right_index=True, how='outer', suffixes=('',''))\n",
    "plot_predictions(df_merged, scaled_df_submission_preds, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_columns = [str(item) + \"_pred\" for item in np.array(range(2002,2008))]\n",
    "true_columns = [str(item) for item in range(2002,2008)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(row, model):\n",
    "    training_data = row.loc['1972':'2002']\n",
    "    test_data = row.loc['2002':'2007']\n",
    "    \n",
    "    nbr_data_points = training_data.count()\n",
    "    if test_data.count()<6 or training_data.count() < 6 :\n",
    "        return  [None]*6\n",
    "    else:\n",
    "        years = training_data.dropna().index.values.astype(np.int).reshape(-1, 1)\n",
    "        values = training_data.dropna().values\n",
    "        \n",
    "        model.fit(years, values)\n",
    "        \n",
    "        #predictions\n",
    "        return model.predict(np.array(range(2002,2008)).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_submission_in_data.dropna(subset=true_columns)\n",
    "# df.loc[:,'1972':'2007'].head()\n",
    "df=df.loc[:,'2005':'2007']\n",
    "df=df.iloc[0:2,:]\n",
    "display(df.head())\n",
    "transformer = PolynomialFeatures(degree=1)\n",
    "df_poly=transformer.fit_transform(df.T)\n",
    "print(df_poly)\n",
    "transformer = PolynomialFeatures(degree=2,interaction_only=False)\n",
    "df_poly=transformer.fit_transform(df.T)\n",
    "print(df_poly)\n",
    "transformer = PolynomialFeatures(degree=2,interaction_only=True)\n",
    "df_poly=transformer.fit_transform(df.T)\n",
    "print(df_poly)\n",
    "# df_simple_preds_true_columns = pd.DataFrame(df.apply(make_prediction, args=(model,),axis=1).tolist(),\\\n",
    "#                                index=df.index, columns=true_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
    "# tried degree 3 but did not look better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_df_submission = df_submission_in_data.loc[:,'1972':'2007']\n",
    "scaled_df_submission = scaled_df_submission.dropna()\n",
    "scaled_df_submission = scaled_df_submission.dropna(subset=true_columns)\n",
    "scaled_df_submission = pd.DataFrame(scaler.fit_transform(scaled_df_submission), \\\n",
    "                                    columns=scaled_df_submission.columns, index=scaled_df_submission.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df_submission_preds = pd.DataFrame(scaled_df_submission.apply(make_prediction, args=(model,),axis=1).tolist(),\\\n",
    "                               index=scaled_df_submission.index, columns=true_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validate(scaled_df_submission, scaled_df_submission_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission_in_data_dropna = df_submission_in_data.dropna(subset=true_columns)\n",
    "df_submission_in_data_no_years = df_submission_in_data_dropna[retained_columns]\n",
    "df_merged = pd.merge(scaled_df_submission, df_submission_in_data_no_years, left_index=True, \\\n",
    "                     right_index=True, how='outer', suffixes=('',''))\n",
    "df_merged.dropna(subset=true_columns,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged = pd.merge(scaled_df_submission, df_submission_in_data_no_years, left_index=True, right_index=True, how='outer', suffixes=('',''))\n",
    "plot_predictions(df_merged, scaled_df_submission_preds, 8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
